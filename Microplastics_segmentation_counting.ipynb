{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTZAKnB46D9a"
      },
      "source": [
        "# Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sK6LYpqZOAJn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2 as cv\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow.keras import backend as K"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4mgkQj_9R5D_"
      },
      "outputs": [],
      "source": [
        "data_dir = \"drive/MyDrive/University/7 semestras/Kursinis/data\"\n",
        "images_dir = os.path.join(data_dir, \"images\")\n",
        "resized_images_dir = os.path.join(data_dir, \"resized_images\")\n",
        "masks_dir = os.path.join(data_dir, \"masks\")\n",
        "resized_masks_dir = os.path.join(data_dir, \"resized_masks\")\n",
        "checkpoint_dir = os.path.join(data_dir, \"checkpoints\")\n",
        "model_augmented_dir = os.path.join(data_dir, \"model_augmented\")\n",
        "checkpoints_augmented_dir = os.path.join(data_dir, \"checkpoints_augmented\")\n",
        "log_dir = os.path.join(data_dir, \"training.log\")\n",
        "figures_dir = os.path.join(data_dir, \"figures\")\n",
        "saved_datasets_dir = os.path.join(data_dir, \"saved_datasets\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MoXJuurETmvd"
      },
      "outputs": [],
      "source": [
        "INPUT_SHAPE = (256, 256)\n",
        "BATCH_SIZE = 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYC-fcHXrcSB"
      },
      "source": [
        "# Base images processing and saving to Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woSlxVA2TCss"
      },
      "source": [
        "First resize all base dataset's images to one size and save, so we don't have to resize them again"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FhWRujmNTPkY"
      },
      "outputs": [],
      "source": [
        "for dir in [images_dir, masks_dir]:\n",
        "  for i, img_name in enumerate(os.listdir(dir)):\n",
        "    image_path = os.path.join(dir, img_name)\n",
        "    img = cv.imread(image_path)\n",
        "    resized_img = cv.resize(img, (INPUT_SHAPE[0], INPUT_SHAPE[1]), interpolation=cv.INTER_AREA)\n",
        "\n",
        "    cv.imwrite(os.path.join(resized_images_dir if \"images\" in dir else resized_masks_dir, img_name), resized_img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mz5GLpeLYH_w"
      },
      "source": [
        "# Utility functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "je8sKoE4cQU4"
      },
      "outputs": [],
      "source": [
        "def show_image(img, cmap='gray'):\n",
        "  plt.imshow(img, cmap=cmap)\n",
        "  plt.show()\n",
        "\n",
        "def show_all_images(*images):\n",
        "  fig = plt.figure(figsize=(10, 7))\n",
        "  # setting values to rows and column variables\n",
        "  rows = 1\n",
        "  columns = len(images)\n",
        "  for i, image in enumerate(images):\n",
        "    # Adds a subplot at the 1st position\n",
        "    fig.add_subplot(rows, columns, i + 1)\n",
        "\n",
        "    # showing image\n",
        "    plt.imshow(image, cmap='gray')\n",
        "    plt.axis('off')\n",
        "\n",
        "def show_images(labels, *images):\n",
        "  fig = plt.figure(figsize=(10, 7))\n",
        "  # setting values to rows and column variables\n",
        "  rows = 1\n",
        "  columns = len(images)\n",
        "\n",
        "  for i, image in enumerate(images):\n",
        "    # Adds a subplot at the 1st position\n",
        "    fig.add_subplot(rows, columns, i + 1)\n",
        "\n",
        "    # showing image\n",
        "    plt.imshow(image, cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.title(labels[i] if i + 1 <= len(labels) else i)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "def save_numpy_as_image(array, path):\n",
        "    \"\"\"\n",
        "    Saves a numpy array as an image.\n",
        "\n",
        "    Parameters:\n",
        "        array (numpy.ndarray): The image data as a numpy array.\n",
        "        path (str): The path where the image will be saved.\n",
        "    \"\"\"\n",
        "    # If the image is binary (i.e., has a shape like (256, 256, 1)),\n",
        "    # we should first remove the singleton dimension before saving it\n",
        "    if array.ndim == 3 and array.shape[-1] == 1:\n",
        "        array = array.squeeze(-1)\n",
        "\n",
        "    # Convert the numpy array to a PIL image\n",
        "    image = Image.fromarray(np.uint8(array * 255))\n",
        "\n",
        "    # Save the image\n",
        "    image.save(path)\n",
        "\n",
        "    print(f\"Image saved as {path}\")"
      ],
      "metadata": {
        "id": "D2c14Hzyp1Pq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgMY22YJFhCf"
      },
      "source": [
        "# Data: preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVAeUY_gab6o"
      },
      "source": [
        "### Load raw images and their masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_RT8brWadOw"
      },
      "outputs": [],
      "source": [
        "def load_images_and_masks(images_dir, masks_dir):\n",
        "  images_arr = []\n",
        "  masks_arr = []\n",
        "  for i, img_name in enumerate(os.listdir(masks_dir)):\n",
        "    image_path = os.path.join(images_dir, img_name)\n",
        "    mask_path = image_path.replace(images_dir, masks_dir)\n",
        "    img = cv.imread(image_path)\n",
        "\n",
        "    if (os.path.isfile(mask_path)):\n",
        "      mask = cv.imread(mask_path, cv.IMREAD_GRAYSCALE)\n",
        "      mask = np.expand_dims(mask, axis=-1)\n",
        "      images_arr.append(img)\n",
        "      masks_arr.append(mask)\n",
        "\n",
        "  return (images_arr, masks_arr)\n",
        "\n",
        "(raw_images, raw_masks) = load_images_and_masks(resized_images_dir, resized_masks_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guFnFJqrzFeE"
      },
      "source": [
        "## Load preprocessed images from drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AckVBMhbYm_"
      },
      "source": [
        "### Load datasets from drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pj4KNJmmbqyN"
      },
      "outputs": [],
      "source": [
        "train_dir = os.path.join(saved_datasets_dir, \"train\")\n",
        "val_dir = os.path.join(saved_datasets_dir, \"val\")\n",
        "test_dir = os.path.join(saved_datasets_dir, \"test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aHlAI3hSbbPM"
      },
      "outputs": [],
      "source": [
        "def load_dataset_from_drive(dir):\n",
        "  images = []\n",
        "  labels = []\n",
        "  all_files = os.listdir(dir)\n",
        "  size = int(len(all_files) / 2)\n",
        "  for i in range(0, size):\n",
        "    image_dir = os.path.join(dir, \"image-\" + str(i) + \".jpg\")\n",
        "    label_dir = os.path.join(dir, \"label-\" + str(i) + \".jpg\")\n",
        "    image = cv.imread(image_dir)\n",
        "    label = cv.imread(label_dir, cv.IMREAD_GRAYSCALE)\n",
        "    label = np.expand_dims(label, axis = -1)\n",
        "    images.append(image)\n",
        "    labels.append(label)\n",
        "\n",
        "  # Normalize the images and masks\n",
        "  images = np.array(images, dtype=np.float32) / 255.0\n",
        "  labels = np.array(labels, dtype=np.float32) / 255.0\n",
        "\n",
        "  return (images, labels)\n",
        "\n",
        "x_train, y_train = load_dataset_from_drive(train_dir)\n",
        "x_val, y_val = load_dataset_from_drive(val_dir)\n",
        "x_test, y_test = load_dataset_from_drive(test_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnW0rpah2h5s"
      },
      "source": [
        "### Convert images to HSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwmjXej02hMi"
      },
      "outputs": [],
      "source": [
        "def convert_rgb_to_hsv(image):\n",
        "  # Convert RGB image to HSV\n",
        "  image = (image * 255).astype(np.uint8)\n",
        "  hsv_image = cv.cvtColor(image, cv.COLOR_RGB2HSV)\n",
        "  return hsv_image / 255.0\n",
        "\n",
        "def convert_dataset_to_hsv(ds_images):\n",
        "  return np.array(list(map(lambda image: convert_rgb_to_hsv(image), ds_images)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aoL-EkKQPqQk"
      },
      "outputs": [],
      "source": [
        "# x_train_hsv = convert_dataset_to_hsv(x_train)\n",
        "# x_val_hsv = convert_dataset_to_hsv(x_val)\n",
        "# x_test_hsv = convert_dataset_to_hsv(x_test)\n",
        "x_train = convert_dataset_to_hsv(x_train)\n",
        "x_val = convert_dataset_to_hsv(x_val)\n",
        "x_test = convert_dataset_to_hsv(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NW6noyQW_47h"
      },
      "source": [
        "### Convert images to greyscale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "378u2_YE_3sX"
      },
      "outputs": [],
      "source": [
        "def convert_rgb_to_greyscale(image):\n",
        "  # Convert RGB image to grey\n",
        "  image = (image * 255).astype(np.uint8)\n",
        "  grey_image = cv.cvtColor(image, cv.COLOR_RGB2GRAY)\n",
        "  return grey_image / 255.0\n",
        "\n",
        "def convert_dataset_to_greyscale(ds_images):\n",
        "  return np.array(list(map(lambda image: convert_rgb_to_greyscale(image), ds_images)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tRyQaN4DABLV"
      },
      "outputs": [],
      "source": [
        "x_train = convert_dataset_to_greyscale(x_train)\n",
        "x_val = convert_dataset_to_greyscale(x_val)\n",
        "x_test = convert_dataset_to_greyscale(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4p6HtsGSAKGZ"
      },
      "outputs": [],
      "source": [
        "x_train = np.expand_dims(x_train, axis=-1)\n",
        "x_val = np.expand_dims(x_val, axis=-1)\n",
        "x_test = np.expand_dims(x_test, axis=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5220VS3YKJM"
      },
      "source": [
        "### Convert images to Gaussian blur"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-rAZgOG8YNGi"
      },
      "outputs": [],
      "source": [
        "def apply_gauss_blur(image, kernel_size=(5, 5), sigma_x=0):\n",
        "  image = (image * 255).astype(np.uint8)\n",
        "  # Apply Gaussian blur\n",
        "  blurred_image = cv.GaussianBlur(image, kernel_size, sigma_x)\n",
        "  return blurred_image / 255.0\n",
        "\n",
        "def convert_dataset_to_gauss_blur(ds_images):\n",
        "  return np.array(list(map(lambda image: apply_gauss_blur(image), ds_images)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJVo61QOY71j"
      },
      "outputs": [],
      "source": [
        "x_train = convert_dataset_to_gauss_blur(x_train)\n",
        "x_val = convert_dataset_to_gauss_blur(x_val)\n",
        "x_test = convert_dataset_to_gauss_blur(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aO76-am9HLx"
      },
      "source": [
        "### Convert images to bilateral blur"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1UhhG3GO9KOg"
      },
      "outputs": [],
      "source": [
        "def apply_bilateral_filter(image, diameter=9, sigma_color=75, sigma_space=75):\n",
        "    image = (image * 255).astype(np.uint8)\n",
        "    # Apply bilateral filter\n",
        "    filtered_image = cv.bilateralFilter(image, diameter, sigma_color, sigma_space)\n",
        "    return filtered_image / 255.0\n",
        "\n",
        "def convert_dataset_to_bilat_blur(ds_images):\n",
        "  return np.array(list(map(lambda image: apply_bilateral_filter(image), ds_images)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5ghjll09UHo"
      },
      "outputs": [],
      "source": [
        "x_train = convert_dataset_to_bilat_blur(x_train)\n",
        "x_val = convert_dataset_to_bilat_blur(x_val)\n",
        "x_test = convert_dataset_to_bilat_blur(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNmT3wgPZl-6"
      },
      "source": [
        "### Convert lists to TF datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5KgFRy6Cmpdt"
      },
      "outputs": [],
      "source": [
        "# Convert your NumPy arrays into a tf.data.Dataset\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "\n",
        "# Cache, shuffle, batch, and prefetch the combined dataset\n",
        "train_dataset = train_dataset.cache().shuffle(buffer_size=1000, reshuffle_each_iteration=True).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "# For the validation dataset, no augmentation is applied\n",
        "val_dataset = val_dataset.batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "# For the test dataset, no augmentation is applied\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KjjFcieF30R"
      },
      "source": [
        "## Preprocess images and split to datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxQAmVEq5GIY"
      },
      "source": [
        "### Define augmentation function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zBuXq_B74Y12"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import random\n",
        "\n",
        "# Apply data augmentation on-the-fly using tf.data and map\n",
        "def augment(image, mask, override_augmentation=None):\n",
        "    number = override_augmentation or random.randint(0, 3)\n",
        "\n",
        "    # Flip the image and mask horizontally\n",
        "    if (number == 0):\n",
        "      new_image = tf.image.flip_left_right(image)\n",
        "      new_mask = tf.image.flip_left_right(mask)\n",
        "    # Flip the image and mask vertically\n",
        "    elif (number == 1):\n",
        "      new_image = tf.image.flip_up_down(image)\n",
        "      new_mask = tf.image.flip_up_down(mask)\n",
        "    # Zoom in 70%\n",
        "    elif (number == 2):\n",
        "      new_image = tf.image.central_crop(image, central_fraction=0.8)  # Zoom in to 70% of the image\n",
        "      new_image = tf.image.resize(new_image, [INPUT_SHAPE[0], INPUT_SHAPE[1]])\n",
        "      new_mask = tf.image.central_crop(mask, central_fraction=0.8)\n",
        "      new_mask = tf.image.resize(new_mask, [INPUT_SHAPE[0], INPUT_SHAPE[1]])\n",
        "    # Randomly rotate the image and mask\n",
        "    # Concatenate image and mask to make sure the same rotation is applied\n",
        "    else:\n",
        "      combined = tf.concat([image, mask], axis=-1)\n",
        "      # rotations = tf.random.uniform(shape=[], minval=1, maxval=4, dtype=tf.int32)\n",
        "      rotations = 1\n",
        "      combined = tf.image.rot90(combined, rotations)\n",
        "      new_image, new_mask = tf.split(combined, [image.shape[-1], mask.shape[-1]], axis=-1)\n",
        "\n",
        "    new_mask = tf.round(new_mask)\n",
        "\n",
        "    return new_image, new_mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fn9tx3iXu_Y"
      },
      "source": [
        "### Normalize and augment images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5310h-zoDUz"
      },
      "outputs": [],
      "source": [
        "# Normalize the images and masks\n",
        "images = np.array(raw_images, dtype=np.float32) / 255.0\n",
        "masks = np.array(raw_masks, dtype=np.float32) / 255.0\n",
        "\n",
        "# Augment the same images\n",
        "augment_fun = lambda image_mask: augment(*image_mask)\n",
        "augmented_pairs = [augment_fun(pair) for pair in zip(images, masks)]\n",
        "augmented_images, augmented_masks = zip(*augmented_pairs)\n",
        "\n",
        "# Concatenate non-augmented and augmented images\n",
        "images = np.concatenate((images, augmented_images), axis=0)\n",
        "masks = np.concatenate((masks, augmented_masks), axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nREtzHps5p4N"
      },
      "source": [
        "### Split to datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pA5eG9FG5nTV"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the dataset\n",
        "x_train, x_temp, y_train, y_temp = train_test_split(images, masks, test_size=0.1, random_state=42)\n",
        "x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Convert your NumPy arrays into a tf.data.Dataset\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "\n",
        "# Cache, shuffle, batch, and prefetch the combined dataset\n",
        "train_dataset = train_dataset.cache().shuffle(buffer_size=1000, reshuffle_each_iteration=True).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "# For the validation dataset, no augmentation is applied\n",
        "val_dataset = val_dataset.batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "# For the test dataset, no augmentation is applied\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1R-cfk8t84M"
      },
      "source": [
        "### Calculate positive (microplastic) class weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFtq8w3lFPKH"
      },
      "outputs": [],
      "source": [
        "TOTAL_PIXELS = 0\n",
        "MP_PIXELS = 0\n",
        "for masks in [y_train, y_val, y_test]:\n",
        "  for mask in masks:\n",
        "    (height, width, _) = mask.shape\n",
        "    TOTAL_PIXELS += (height * width)\n",
        "    MP_PIXELS += np.count_nonzero(mask > 0)\n",
        "\n",
        "print(TOTAL_PIXELS, MP_PIXELS)\n",
        "POS_WEIGHT = (1 / (MP_PIXELS / TOTAL_PIXELS))\n",
        "print(\"POS_WEIGHT\", POS_WEIGHT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBNmHQ7kGAgA"
      },
      "source": [
        "# Model: model building and training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q51THrs85kxW"
      },
      "source": [
        "### Build model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YHf8DbjjJ6Uy"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, concatenate, Conv2DTranspose, Dropout\n",
        "\n",
        "# def build_unet_model(input_shape, num_filters=32, activation = 'relu'):\n",
        "def build_unet_model(input_shape, num_filters=64, activation = 'relu'):\n",
        "  inputs = Input(input_shape)\n",
        "\n",
        "  c1 = Conv2D(num_filters, (3, 3), activation=activation, kernel_initializer='HeNormal', padding='same') (inputs)\n",
        "  c1 = Conv2D(num_filters, (3, 3), activation=activation, kernel_initializer='HeNormal', padding='same') (c1)\n",
        "  p1 = MaxPooling2D((2, 2)) (c1)\n",
        "\n",
        "  c2 = Conv2D(num_filters*2, (3, 3), activation=activation, kernel_initializer='HeNormal', padding='same') (p1)\n",
        "  c2 = Conv2D(num_filters*2, (3, 3), activation=activation, kernel_initializer='HeNormal', padding='same') (c2)\n",
        "  p2 = MaxPooling2D((2, 2)) (c2)\n",
        "\n",
        "  c3 = Conv2D(num_filters*4, (3, 3), activation=activation, kernel_initializer='HeNormal', padding='same') (p2)\n",
        "  c3 = Conv2D(num_filters*4, (3, 3), activation=activation, kernel_initializer='HeNormal', padding='same') (c3)\n",
        "  p3 = MaxPooling2D((2, 2)) (c3)\n",
        "\n",
        "  c4 = Conv2D(num_filters*8, (3, 3), activation=activation, kernel_initializer='HeNormal', padding='same') (p3)\n",
        "  c4 = Conv2D(num_filters*8, (3, 3), activation=activation, kernel_initializer='HeNormal', padding='same') (c4)\n",
        "  p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
        "\n",
        "  c5 = Conv2D(num_filters*16, (3, 3), activation=activation, kernel_initializer='HeNormal', padding='same') (p4)\n",
        "  c5 = Conv2D(num_filters*16, (3, 3), activation=activation, kernel_initializer='HeNormal', padding='same') (c5)\n",
        "\n",
        "  u6 = Conv2DTranspose(num_filters*8, (2, 2), strides=(2, 2), padding='same') (c5)\n",
        "  u6 = concatenate([u6, c4])\n",
        "  c6 = Conv2D(num_filters*8, (3, 3), activation=activation, kernel_initializer='HeNormal', padding='same') (u6)\n",
        "  c6 = Conv2D(num_filters*8, (3, 3), activation=activation, kernel_initializer='HeNormal', padding='same') (c6)\n",
        "\n",
        "  u7 = Conv2DTranspose(num_filters*4, (2, 2), strides=(2, 2), padding='same') (c6)\n",
        "  u7 = concatenate([u7, c3])\n",
        "  c7 = Conv2D(num_filters*4, (3, 3), activation=activation, kernel_initializer='HeNormal', padding='same') (u7)\n",
        "  c7 = Conv2D(num_filters*4, (3, 3), activation=activation, kernel_initializer='HeNormal', padding='same') (c7)\n",
        "\n",
        "  u8 = Conv2DTranspose(num_filters*2, (2, 2), strides=(2, 2), padding='same') (c7)\n",
        "  u8 = concatenate([u8, c2])\n",
        "  c8 = Conv2D(num_filters*2, (3, 3), activation=activation, kernel_initializer='HeNormal', padding='same') (u8)\n",
        "  c8 = Conv2D(num_filters*2, (3, 3), activation=activation, kernel_initializer='HeNormal', padding='same') (c8)\n",
        "\n",
        "  u9 = Conv2DTranspose(num_filters, (2, 2), strides=(2, 2), padding='same') (c8)\n",
        "  u9 = concatenate([u9, c1], axis=3)\n",
        "  c9 = Conv2D(num_filters, (3, 3), activation=activation, kernel_initializer='HeNormal', padding='same') (u9)\n",
        "  c9 = Conv2D(num_filters, (3, 3), activation=activation, kernel_initializer='HeNormal', padding='same') (c9)\n",
        "\n",
        "  outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
        "\n",
        "  model = Model(inputs=[inputs], outputs=[outputs])\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWUWHPKGJ0Mk"
      },
      "source": [
        "### Create F1 metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eWEZ05CCi0BS"
      },
      "outputs": [],
      "source": [
        "# Custom F1 metric function\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.metrics import Metric\n",
        "\n",
        "class F1Score(Metric):\n",
        "    def __init__(self, name='f1_score', threshold=0.5, **kwargs):\n",
        "        super(F1Score, self).__init__(name=name, **kwargs)\n",
        "        self.threshold = threshold\n",
        "        self.precision = tf.keras.metrics.Precision()\n",
        "        self.recall = tf.keras.metrics.Recall()\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        y_pred = tf.where(y_pred > self.threshold, 1., 0.)\n",
        "        y_true = tf.reshape(y_true, shape=(-1,))\n",
        "        y_pred = tf.reshape(y_pred, shape=(-1,))\n",
        "\n",
        "        self.precision.update_state(y_true, y_pred, sample_weight)\n",
        "        self.recall.update_state(y_true, y_pred, sample_weight)\n",
        "\n",
        "    def result(self):\n",
        "        precision = self.precision.result()\n",
        "        recall = self.recall.result()\n",
        "        return 2 * ((precision * recall) / (precision + recall + tf.keras.backend.epsilon()))\n",
        "\n",
        "    def reset_state(self):\n",
        "        self.precision.reset_states()\n",
        "        self.recall.reset_states()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWIH6YsTuNg5"
      },
      "source": [
        "### Define loss functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AM6AWhJwnw85"
      },
      "outputs": [],
      "source": [
        "POS_WEIGHT = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mx-YzQOpaW7a"
      },
      "outputs": [],
      "source": [
        "def weighted_binary_crossentropy(pos_weight):\n",
        "    \"\"\"\n",
        "    A weighted version of keras.objectives.binary_crossentropy\n",
        "    Variables:\n",
        "        pos_weight: A coefficient to use on the positive classes\n",
        "    \"\"\"\n",
        "    def loss(y_true, y_pred):\n",
        "        # Transform to logits\n",
        "        epsilon = tf.keras.backend.epsilon()\n",
        "        y_pred = tf.clip_by_value(y_pred, epsilon, 1 - epsilon)\n",
        "        y_pred_logit = tf.math.log(y_pred / (1 - y_pred))\n",
        "\n",
        "        loss = tf.nn.weighted_cross_entropy_with_logits(logits=y_pred_logit, labels=y_true, pos_weight=pos_weight)\n",
        "        return tf.reduce_mean(loss, axis=-1)\n",
        "\n",
        "    return loss\n",
        "\n",
        "wbce = weighted_binary_crossentropy(POS_WEIGHT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWM0Dq9QC4Ok"
      },
      "outputs": [],
      "source": [
        "def dice_coef(y_true, y_pred, smooth):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    dice = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "    return dice\n",
        "\n",
        "\n",
        "def dice_loss(y_true, y_pred, smooth = 1e-5):\n",
        "    return 1 - dice_coef(y_true, y_pred, smooth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pq_Cd08oBNEk"
      },
      "outputs": [],
      "source": [
        "def dice_with_wbce(y_true, y_pred):\n",
        "  dice_loss_val = dice_loss(y_true, y_pred)\n",
        "  wbce_loss_val = wbce(y_true, y_pred)\n",
        "  return dice_loss_val + wbce_loss_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32YzvA5WCrPV"
      },
      "outputs": [],
      "source": [
        "smooth = 1e-5\n",
        "alpha = 0.3\n",
        "gamma = 4/3\n",
        "\n",
        "def tversky_index(y_true, y_pred):\n",
        "    y_true_pos = K.flatten(y_true)\n",
        "    y_pred_pos = K.flatten(y_pred)\n",
        "    true_pos = K.sum(y_true_pos * y_pred_pos)\n",
        "    false_neg = K.sum(y_true_pos * (1 - y_pred_pos))\n",
        "    false_pos = K.sum((1 - y_true_pos) * y_pred_pos)\n",
        "    return (true_pos + smooth) / (true_pos + alpha * false_neg + (\n",
        "            1 - alpha) * false_pos + smooth)\n",
        "\n",
        "def tversky_loss(y_true, y_pred):\n",
        "    return 1 - tversky_index(y_true, y_pred)\n",
        "\n",
        "def focal_tversky(y_true, y_pred):\n",
        "    pt_1 = tversky_index(y_true, y_pred)\n",
        "    return K.pow((1 - pt_1), gamma)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d51sdFTOBH0u"
      },
      "source": [
        "### Compile the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uP0KcNNafDKw"
      },
      "outputs": [],
      "source": [
        "# Define threshold for determining if model output is MP or background\n",
        "THRESHOLD = 0.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ppQVd6C6MGXN"
      },
      "outputs": [],
      "source": [
        "# Instantiate the U-Net model\n",
        "input_shape = (256, 256, 3)\n",
        "# input_shape = (256, 256, 1)\n",
        "\n",
        "\n",
        "def build_and_compile_model():\n",
        "  unet_model = build_unet_model(input_shape)\n",
        "  # unet_model = build_unet_model(input_shape, activation = 'leaky_relu')\n",
        "  # Create an optimizer with the learning rate schedule\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=0.00001, weight_decay=0.0001)\n",
        "  # optimizer = tf.keras.optimizers.Adam(learning_rate=1.2500e-06, weight_decay=0.0001)\n",
        "  # optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001, weight_decay=0.0001)\n",
        "\n",
        "  metrics = [\n",
        "    'accuracy',\n",
        "    tf.keras.metrics.BinaryIoU(target_class_ids=[0, 1], threshold=THRESHOLD, name=\"binary_io_u\"),\n",
        "    tf.keras.metrics.Precision(thresholds=THRESHOLD, name=\"precision\"),\n",
        "    tf.keras.metrics.Recall(thresholds=THRESHOLD, name=\"recall\"),\n",
        "    F1Score(threshold=THRESHOLD, name=\"f1_score\")\n",
        "  ]\n",
        "\n",
        "  # Compile model with custom loss function\n",
        "  # unet_model.compile(optimizer=optimizer, loss=wbce, metrics=metrics)\n",
        "  # unet_model.compile(optimizer=optimizer, loss=dice_loss, metrics=metrics)\n",
        "  # unet_model.compile(optimizer=optimizer, loss=dice_with_wbce, metrics=metrics)\n",
        "  # unet_model.compile(optimizer=optimizer, loss=focal_loss, metrics=metrics)\n",
        "  unet_model.compile(optimizer=optimizer, loss=focal_tversky, metrics=metrics)\n",
        "\n",
        "  return unet_model\n",
        "\n",
        "unet_model = build_and_compile_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWUoYri4826z"
      },
      "source": [
        "### Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJhyKNs1TVoD"
      },
      "outputs": [],
      "source": [
        "unet_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGHMT5FZ68o7"
      },
      "source": [
        "## Setup model directories"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9JLYJXAoUsJ"
      },
      "source": [
        "### Coursework models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHnF-bn3oQVw"
      },
      "outputs": [],
      "source": [
        "# Model names\n",
        "dice_smooth_1eminus5_thresh_90 = \"dice_smooth_1eminus5_thresh_90\"\n",
        "dice_smooth_1_thresh_90 = \"dice_smooth_1_thresh_90\"\n",
        "dice_smooth_1eminus5_thresh_70 = \"dice_smooth_1eminus5_thresh_70\"\n",
        "dice_smooth_1eminus5_thresh_50 = \"dice_smooth_1eminus5_thresh_50\"\n",
        "dice_smooth_1eminus5_thresh_70_relu = \"dice_smooth_1eminus5_thresh_70_relu\"\n",
        "dice_smooth_1eminus5_thresh_50_relu = \"dice_smooth_1eminus5_thresh_50_relu\"\n",
        "\n",
        "dice_smooth_1eminus5_thresh_50_relu_batch_4_filters_64 = \"dice_smooth_1eminus5_thresh_50_relu_batch_4_filters_64\"\n",
        "\n",
        "wbce_208_thresh_90 = \"wbce_208_thresh_90\"\n",
        "wbce_208_thresh_70 = \"wbce_208_thresh_70\"\n",
        "wbce_208_thresh_70_relu = \"wbce_208_thresh_70_relu\"\n",
        "wbce_208_thresh_50 = \"wbce_208_thresh_50\"\n",
        "wbce_208_thresh_50_relu = \"wbce_208_thresh_50_relu\"\n",
        "wbce_200_thresh_50_relu_batch_4_filters_64 = \"wbce_200_thresh_50_relu_batch_4_filters_64\"\n",
        "\n",
        "dice_smooth_1eminus5_wbce_208_thresh_90 = \"dice_smooth_1eminus5_wbce_208_thresh_90\"\n",
        "dice_smooth_1eminus5_wbce_208_thresh_70 = \"dice_smooth_1eminus5_wbce_208_thresh_70\"\n",
        "dice_smooth_1eminus5_wbce_208_thresh_50 = \"dice_smooth_1eminus5_wbce_208_thresh_50\"\n",
        "dice_smooth_1eminus5_wbce_208_thresh_70_relu = \"dice_smooth_1eminus5_wbce_208_thresh_70_relu\"\n",
        "dice_smooth_1eminus5_wbce_208_thresh_50_relu = \"dice_smooth_1eminus5_wbce_208_thresh_50_relu\"\n",
        "dice_smooth_1eminus5_wbce_208_thresh_50_relu_2 = \"dice_smooth_1eminus5_wbce_208_thresh_50_relu_2\"\n",
        "\n",
        "dice_smooth_1eminus5_wbce_200_thresh_50_relu_batch_4_filters_64 = \"dice_smooth_1eminus5_wbce_200_thresh_50_relu_batch_4_filters_64\"\n",
        "\n",
        "focal_gamma_15_alpha_193_relu = \"focal_gamma_15_alpha_193_relu\"\n",
        "focal_gamma_11_alpha_193_relu = \"focal_gamma_11_alpha_193_relu\"\n",
        "focal_gamma_2_alpha_193_relu = \"focal_gamma_2_alpha_193_relu\"\n",
        "focal_gamma_3_alpha_193_relu = \"focal_gamma_3_alpha_193_relu\"\n",
        "focal_gamma_15_alpha_100_relu = \"focal_gamma_15_alpha_100_relu\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLiR93ntoYy5"
      },
      "source": [
        "### Bachelor thesis model names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sxk75ksntG31"
      },
      "outputs": [],
      "source": [
        "# BACHELOR THESIS MODEL NAMES\n",
        "model_names = {\n",
        "    \"binary_focal_ce_1\": \"binary_focal_ce_1\",\n",
        "    \"binary_focal_ce_2\": \"binary_focal_ce_2\",\n",
        "    \"binary_focal_ce_3\": \"binary_focal_ce_3\",\n",
        "    \"binary_focal_ce_4\": \"binary_focal_ce_4\",\n",
        "    \"dice_wbce_1\": \"dice_wbce_1\",\n",
        "    \"dice_wbce_1_hsv\": \"dice_wbce_1_hsv\",\n",
        "    \"dice_wbce_1_grey\": \"dice_wbce_1_grey\",\n",
        "    \"dice_wbce_1_gauss\": \"dice_wbce_1_gauss\",\n",
        "    \"dice_wbce_1_bilat\": \"dice_wbce_1_bilat\",\n",
        "    \"dice_wbce_1_32flt\": \"dice_wbce_1_32flt\",\n",
        "    \"dice_wbce_1_leakyrelu\": \"dice_wbce_1_leakyrelu\",\n",
        "    \"dice_wbce_1_batch8\": \"dice_wbce_1_batch8\",\n",
        "    \"dice_wbce_1_lr_scheduler\": \"dice_wbce_1_lr_scheduler\",\n",
        "    \"dice_wbce_2\": \"dice_wbce_2\",\n",
        "    \"dice_wbce_3\": \"dice_wbce_3\",\n",
        "    \"dice_wbce_4\": \"dice_wbce_4\",\n",
        "    \"dice_wbce_5\": \"dice_wbce_5\",\n",
        "    \"dice_wbce_6\": \"dice_wbce_6\",\n",
        "    \"dice_1\": \"dice_1\",\n",
        "    \"wbce_1\": \"wbce_1\",\n",
        "    \"wbce_2\": \"wbce_2\",\n",
        "    \"wbce_3\": \"wbce_3\",\n",
        "    \"wbce_4\": \"wbce_4\",\n",
        "    \"focal_tversky_1\": \"focal_tversky_1\",\n",
        "    \"focal_tversky_2\": \"focal_tversky_2\",\n",
        "    \"focal_tversky_3\": \"focal_tversky_3\",\n",
        "    \"focal_tversky_4\": \"focal_tversky_4\",\n",
        "    \"focal_tversky_5\": \"focal_tversky_5\",\n",
        "    \"focal_tversky_5_hsv\": \"focal_tversky_5_hsv\",\n",
        "    \"focal_tversky_6\": \"focal_tversky_6\",\n",
        "    \"focal_tversky_7\": \"focal_tversky_7\",\n",
        "    \"focal_tversky_8\": \"focal_tversky_8\",\n",
        "    \"focal_tversky_8_hsv\": \"focal_tversky_8_hsv\",\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reEcmXyeosyI"
      },
      "source": [
        "### Current model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_current_model(name):\n",
        "  global current_model, current_logger_dir, current_model_dir\n",
        "  current_model = model_names[name]\n",
        "  current_logger_dir = os.path.join(training_logs_dir, current_model + \".log\")\n",
        "  current_model_dir = os.path.join(models_dir, current_model)"
      ],
      "metadata": {
        "id": "1SmHyYEfyd87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gzDpAD5covcH"
      },
      "outputs": [],
      "source": [
        "current_model = None\n",
        "training_logs_dir = os.path.join(data_dir, \"training_logs\")\n",
        "current_logger_dir = None\n",
        "models_dir = os.path.join(data_dir, \"models\")\n",
        "\n",
        "set_current_model('focal_tversky_5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4SPfEOoolhw"
      },
      "source": [
        "## Model callbacks, model loading and training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKOG03K12Ijp"
      },
      "source": [
        "### Setup callbacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "709PEu7JOflv"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger, LearningRateScheduler\n",
        "\n",
        "checkpoints_augmented_dir = os.path.join(data_dir, \"checkpoints_augmented\")\n",
        "checkpoint_dir_with_epochs = os.path.join(checkpoints_augmented_dir, current_model + \".weights.{epoch:02d}-{val_loss:.3f}.hdf5\")\n",
        "# checkpoint_dir_with_epochs = os.path.join(checkpoints_augmented_dir, current_model + \".weights.2.{epoch:02d}-{val_loss:.3f}.hdf5\")\n",
        "\n",
        "# Set up callback for saving model architecture and weights\n",
        "model_checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=checkpoint_dir_with_epochs,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_loss',\n",
        "    save_best_only=False,\n",
        "    mode='min',\n",
        ")\n",
        "\n",
        "# Callback for logging model mettrics\n",
        "csv_logger_callback = CSVLogger(current_logger_dir)\n",
        "\n",
        "# Set up callback to reduce learning_rate when val_loss plateaus\n",
        "reduce_lr_callback = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10)\n",
        "\n",
        "def scheduler(epoch, lr):\n",
        "    if epoch < 20:\n",
        "        return lr\n",
        "    else:\n",
        "      if (epoch - 20) % 20 == 0:\n",
        "        return lr * 0.5\n",
        "      else:\n",
        "        return lr\n",
        "\n",
        "scheduler_callback = LearningRateScheduler(scheduler)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lc8zgTcUmPFT"
      },
      "source": [
        "### Load model from storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "roaLjzW5mJ62"
      },
      "outputs": [],
      "source": [
        "print(current_model_dir)\n",
        "unet_model = tf.keras.saving.load_model(\n",
        "    current_model_dir,\n",
        "    custom_objects={\n",
        "        # \"loss\": wbce,\n",
        "        \"F1Score\": F1Score,\n",
        "        \"dice_with_wbce\": dice_with_wbce,\n",
        "        \"dice_loss\": dice_loss,\n",
        "        # \"weighted_binary_crossentropy\": wbce,\n",
        "        \"wbce\": wbce,\n",
        "        \"focal_tversky\": focal_tversky\n",
        "    },\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ft4dgC4kKEUe",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# checkpoint_dir = os.path.join(checkpoints_augmented_dir, current_model + \".weights.85-0.000.hdf5\")\n",
        "checkpoint_dir = os.path.join(checkpoints_augmented_dir, \"dice_wbce_5.weights.24-0.928.hdf5\")\n",
        "unet_model.load_weights(checkpoint_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0MiRODlmK7a"
      },
      "source": [
        "### Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfw0C0fWNMWQ"
      },
      "outputs": [],
      "source": [
        "print(\"Now training:\", current_model, unet_model.loss)\n",
        "# Train the model\n",
        "history = unet_model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    callbacks=[model_checkpoint_callback, csv_logger_callback, reduce_lr_callback, scheduler_callback],\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=120\n",
        "    # epochs=96\n",
        "    # epochs=24\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "giTDg3j9mGWR"
      },
      "outputs": [],
      "source": [
        "unet_model.save(current_model_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lwmzikav5vZT"
      },
      "source": [
        "# Model evaluation and testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tN2YmKwY6BdA"
      },
      "source": [
        "### Evaluate and predict test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eM_6MeJnM_dy"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "print(\"Current model\", current_model)\n",
        "# scores = unet_model.evaluate(x_test, y_test)\n",
        "\n",
        "start = time.time()\n",
        "base_predictions = unet_model.predict(x_test)\n",
        "# base_predictions = unet_model.predict(x_val)\n",
        "# base_predictions = unet_model.predict(x_train)\n",
        "end = time.time()\n",
        "print(\"time\", end - start)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0CLWQD4txme"
      },
      "source": [
        "### Apply thresholding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eWRQih6dtvJb"
      },
      "outputs": [],
      "source": [
        "def apply_threshold(image, threshold=THRESHOLD):\n",
        "  threshold = threshold * 255\n",
        "  image = image * 255.0\n",
        "  image = image.astype(np.uint8)\n",
        "  ret, image = cv.threshold(image, threshold, 255, cv.THRESH_BINARY)\n",
        "  return np.expand_dims(image, axis=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTKMrPUJnPxB"
      },
      "source": [
        "### Test out morphological operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXj1r_f7o7x4"
      },
      "outputs": [],
      "source": [
        "from scipy.ndimage import binary_dilation, binary_erosion\n",
        "\n",
        "def apply_erosion_dilation(image):\n",
        "  # Remove the singleton dimension\n",
        "  image = np.squeeze(image, axis=-1)\n",
        "\n",
        "  # Define the structuring element (kernel) for dilation and erosion\n",
        "  # You can adjust the size and shape of the structuring element based on your requirements\n",
        "  struct_elem_size = 3\n",
        "  structuring_element = tf.ones((struct_elem_size, struct_elem_size))\n",
        "\n",
        "  # Apply dilation\n",
        "  dilated_mask = tf.numpy_function(binary_dilation, [image, structuring_element], tf.float32)\n",
        "\n",
        "  # Apply erosion to the dilated mask\n",
        "  eroded_mask = tf.numpy_function(binary_erosion, [dilated_mask, structuring_element], tf.float32)\n",
        "\n",
        "  # return eroded_mask\n",
        "  return np.expand_dims(eroded_mask, axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dgsDZ85tnTRi"
      },
      "outputs": [],
      "source": [
        "def calculate_f1(label, prediction):\n",
        "  # Create an instance of the F1Score metric\n",
        "  f1_score = F1Score()\n",
        "  f1_score.update_state(label, prediction)\n",
        "  # Get the F1 score\n",
        "  result = f1_score.result().numpy()\n",
        "  return result\n",
        "\n",
        "def calculate_iou(label, prediction):\n",
        "  # Create an instance of the BinaryIoU metric\n",
        "  binary_iou = tf.keras.metrics.BinaryIoU(target_class_ids=[0, 1], threshold=THRESHOLD)\n",
        "  # Update the state of the BinaryIoU metric with the predicted and actual masks\n",
        "  binary_iou.update_state(label, prediction)\n",
        "  # Get the IoU value\n",
        "  result = binary_iou.result().numpy()\n",
        "  return result;\n",
        "\n",
        "def calculate_metrics_for_single_prediction(label, prediction):\n",
        "  f1_score = calculate_f1(label, prediction)\n",
        "  iou_score = calculate_iou(label, prediction)\n",
        "  return f1_score, iou_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "knl_g-A7i6mk"
      },
      "outputs": [],
      "source": [
        "from statistics import mean\n",
        "zipped_test_ds = list(zip(x_test, y_test))\n",
        "\n",
        "def calculate_metrics_for_predictions(predictions):\n",
        "\n",
        "  f1_og_list = []; iou_og_list = [];\n",
        "  f1_mod_list = []; iou_mod_list = [];\n",
        "\n",
        "  for (i, (image, label)) in enumerate(zipped_test_ds):\n",
        "    prediction = predictions[i]\n",
        "    prediction = apply_threshold(prediction)\n",
        "    prediction_with_morph = apply_erosion_dilation(prediction)\n",
        "\n",
        "    f1_og, iou_og = calculate_metrics_for_single_prediction(label, prediction)\n",
        "    f1_mod, iou_mod = calculate_metrics_for_single_prediction(label, prediction_with_morph)\n",
        "\n",
        "    f1_og_list.append(f1_og); iou_og_list.append(iou_og);\n",
        "    f1_mod_list.append(f1_mod); iou_mod_list.append(iou_mod);\n",
        "    # show_all_images(prediction, prediction_with_morph)\n",
        "    # show_all_images(label, image, base_predictions[i])\n",
        "\n",
        "  print(f\" F1: from {mean(f1_og_list)}, to {mean(f1_mod_list)}\")\n",
        "  print(f\"IoU: from {mean(iou_og_list)}, to {mean(iou_mod_list)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BmyOCiykvJ3z"
      },
      "outputs": [],
      "source": [
        "calculate_metrics_for_predictions(base_predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPEgLw4E6NAm"
      },
      "source": [
        "### Counting microplastics from masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bA_LZ0660eLJ"
      },
      "outputs": [],
      "source": [
        "def count_blobs(image):\n",
        "  image = image * 255.0\n",
        "  image = image.astype(np.uint8)\n",
        "\n",
        "  # Calculate connected components, aka how many MP instances were found in image\n",
        "  blob_count, _ = cv.connectedComponents(image)\n",
        "  blob_count -= 1 # Deduct one component, which is the background\n",
        "\n",
        "  return blob_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZZBNUf5qSE8"
      },
      "outputs": [],
      "source": [
        "counting_dir = os.path.join(figures_dir, \"counting\")\n",
        "predicted_dir = os.path.join(figures_dir, \"predicted_dataset\")\n",
        "morph_improvement_dir = os.path.join(figures_dir, \"morph_improvement\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_image_to_predicted(image, name, index, dir=predicted_dir):\n",
        "  save_numpy_as_image(image, os.path.join(dir, str(index) + \"_\" + name + \".png\"))"
      ],
      "metadata": {
        "id": "AFpruEe0qKd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZD5n4DSKX_m",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "FILTER_THRESHOLD = THRESHOLD\n",
        "\n",
        "def count_image_blobs(images, labels, predictions = base_predictions, save_counts=False, model_name=None, from_ind=0, to_ind=9999):\n",
        "  images = images[from_ind:to_ind]\n",
        "  labels = labels[from_ind:to_ind]\n",
        "  total_mp_predicted = 0\n",
        "  total_mp_predicted_morph = 0\n",
        "  total_mp_actual = 0\n",
        "  total_correct = 0\n",
        "  total_correct_morph = 0\n",
        "\n",
        "  data = {'predicted': [], 'actual': []}\n",
        "\n",
        "  abs_errors = []; abs_errors_morph = []\n",
        "  sq_errors = []; sq_errors_morph = []\n",
        "\n",
        "  for i, (image, label) in enumerate(zip(images, labels)):\n",
        "    abs_index = i + from_ind\n",
        "    prediction = predictions[abs_index]\n",
        "    prediction = apply_threshold(prediction)\n",
        "    prediction_with_morph = apply_erosion_dilation(prediction)\n",
        "    label = apply_threshold(label, threshold=0.5)\n",
        "\n",
        "    predicted_count = count_blobs(prediction)\n",
        "    predicted_morph_count = count_blobs(prediction_with_morph)\n",
        "    actual_count = count_blobs(label)\n",
        "\n",
        "    diff = abs(actual_count - predicted_count)\n",
        "    diff_morph = abs(actual_count - predicted_morph_count)\n",
        "\n",
        "    abs_errors.append(diff)\n",
        "    abs_errors_morph.append(diff_morph)\n",
        "    sq_errors.append(diff ** 2)\n",
        "    sq_errors_morph.append(diff_morph ** 2)\n",
        "\n",
        "    if (predicted_count == actual_count):\n",
        "      total_correct += 1\n",
        "\n",
        "    if (predicted_morph_count == actual_count):\n",
        "      total_correct_morph += 1\n",
        "\n",
        "    data['predicted'].append(predicted_count)\n",
        "    data['actual'].append(actual_count)\n",
        "\n",
        "    total_mp_predicted += predicted_count\n",
        "    total_mp_actual += actual_count\n",
        "    total_mp_predicted_morph += predicted_morph_count\n",
        "\n",
        "    # if (predicted_count != predicted_morph_count):\n",
        "    if (True):\n",
        "      print(f'Image {abs_index}: predicted {predicted_count}, predicted with morph {predicted_morph_count}, actual {actual_count}')\n",
        "      show_images([abs_index, predicted_count, predicted_morph_count, actual_count], image, prediction, prediction_with_morph, label)\n",
        "      save_image_to_predicted(image, \"image\", i, dir=morph_improvement_dir)\n",
        "      save_image_to_predicted(label / 255.0, \"label\", i, dir=morph_improvement_dir)\n",
        "      save_image_to_predicted(prediction / 255.0, \"prediction\", i, dir=morph_improvement_dir)\n",
        "      save_image_to_predicted(prediction_with_morph, \"prediction_morph\", i, dir=morph_improvement_dir)\n",
        "\n",
        "  mae = sum(abs_errors) / len(images)\n",
        "  mae_morph = sum(abs_errors_morph) / len(images)\n",
        "  mse = sum(sq_errors) / len(images)\n",
        "  mse_morph = sum(sq_errors_morph) / len(images)\n",
        "  deviation = abs(total_mp_predicted - total_mp_actual) / total_mp_actual\n",
        "  deviation_morph = abs(total_mp_predicted_morph - total_mp_actual) / total_mp_actual\n",
        "\n",
        "  # Construct dataframe and save\n",
        "  if (save_counts):\n",
        "    dataframe = pd.DataFrame(data=data)\n",
        "    dataframe.to_csv(os.path.join(counting_dir, model_name + \".csv\"))\n",
        "\n",
        "  return total_mp_predicted, total_mp_predicted_morph, total_mp_actual, total_correct, total_correct_morph, mae, mae_morph, mse, mse_morph, deviation, deviation_morph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Abg0JxtecXK"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "total_mp_predicted, total_mp_predicted_morph, total_mp_actual, total_correct, total_correct_morph, mae, mae_morph, mse, mse_morph, deviation, deviation_morph = count_image_blobs(x_test, y_test, save_counts=True, model_name=\"combo\")\n",
        "end = time.time()\n",
        "print(\"time:\", end - start)\n",
        "\n",
        "print(f'Counting with model {current_model}:')\n",
        "print(f'Total predicted {total_mp_predicted}, total predicted morph {total_mp_predicted_morph}, total actual: {total_mp_actual}')\n",
        "print(f'Num correct {total_correct}, num correct morph {total_correct_morph}')\n",
        "print(f'Prop correct {round(total_correct / len(x_test) * 100, 2)}%, prop correct morph {round(total_correct_morph / len(x_test) * 100, 2)}%')\n",
        "print(f'MAE {mae}, MAE morph {mae_morph}')\n",
        "print(f'MSE {mse}, MSE morph {mse_morph}')\n",
        "print(f'Deviation {round(deviation * 100, 2)}%, deviation morph {round(deviation_morph * 100, 2)}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwfhtbiXkcgK"
      },
      "source": [
        "### Evaluate model each 10 epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WzH3ogyekan1"
      },
      "outputs": [],
      "source": [
        "all_checkpoints = os.listdir(checkpoints_augmented_dir)\n",
        "filtered_checkpoints = list(filter(lambda checkpoint: True if checkpoint.startswith(current_model) else False, all_checkpoints))\n",
        "\n",
        "def load_model_and_test(checkpoint):\n",
        "  checkpoint_dir = os.path.join(checkpoints_augmented_dir, checkpoint)\n",
        "  print(\"\\nCurrent checkpoint\", checkpoint)\n",
        "  unet_model = build_and_compile_model()\n",
        "\n",
        "  predictions = unet_model.predict(x_test)\n",
        "  calculate_metrics_for_predictions(predictions)\n",
        "\n",
        "  total_mp_predicted, total_mp_predicted_morph, total_mp_actual, total_correct, total_correct_morph, mae, mae_morph, mse, mse_morph, deviation, deviation_morph = count_image_blobs(x_test, y_test, predictions=predictions, model_name=current_model)\n",
        "\n",
        "  print(f'Total predicted {total_mp_predicted}, total predicted morph {total_mp_predicted_morph}, total actual: {total_mp_actual}')\n",
        "  print(f'Num correct {total_correct}, num correct morph {total_correct_morph}')\n",
        "  print(f'Prop correct {round(total_correct / len(x_test) * 100, 2)}%, prop correct morph {round(total_correct_morph / len(x_test) * 100, 2)}%')\n",
        "  print(f'MAE {mae}, MAE morph {mae_morph}')\n",
        "  print(f'MSE {mse}, MSE morph {mse_morph}')\n",
        "  print(f'Deviation {round(deviation * 100, 2)}%, deviation morph {round(deviation_morph * 100, 2)}%')\n",
        "\n",
        "for count, checkpoint in enumerate(filtered_checkpoints, 1): # Start counting from 1\n",
        "  # if count % 10 == 0:\n",
        "  load_model_and_test(checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tL8_K3MsP-Zf"
      },
      "outputs": [],
      "source": [
        "all_checkpoints = os.listdir(checkpoints_augmented_dir)\n",
        "filtered_checkpoints = list(filter(lambda checkpoint: True if checkpoint.startswith(current_model) else False, all_checkpoints))\n",
        "\n",
        "for count, checkpoint in enumerate(filtered_checkpoints, 1): # Start counting from 1\n",
        "  if count % 10 != 0:\n",
        "    os.remove(os.path.join(checkpoints_augmented_dir, checkpoint))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdNjdgWK3JW9"
      },
      "source": [
        "### Model metrics graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kT4L2e1Lqyw2"
      },
      "source": [
        "### Show metric graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0dNp5yJh4cN"
      },
      "outputs": [],
      "source": [
        "# Show metric graphs\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def show_training_metrics(data):\n",
        "  # Plot training and validation accuracy\n",
        "  plt.figure(figsize=(12, 6))\n",
        "  plt.subplot(2, 2, 1)\n",
        "  plt.plot(data['epoch'], data['accuracy'], label='Training Accuracy')\n",
        "  plt.plot(data['epoch'], data['val_accuracy'], label='Validation Accuracy')\n",
        "  plt.title('Training and Validation Accuracy')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.legend()\n",
        "\n",
        "  # Plot training and validation loss\n",
        "  plt.subplot(2, 2, 2)\n",
        "  plt.plot(data['epoch'], data['loss'], label='Training Loss')\n",
        "  plt.plot(data['epoch'], data['val_loss'], label='Validation Loss')\n",
        "  plt.title('Training and Validation Loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "\n",
        "  # Plot validation F1 Score, Precision, and Recall\n",
        "  plt.subplot(2, 2, 3)\n",
        "  plt.plot(data['epoch'], data['val_f1_score'], label='Validation F1 Score')\n",
        "  plt.plot(data['epoch'], data['val_precision'], label='Validation Precision')\n",
        "  plt.plot(data['epoch'], data['val_recall'], label='Validation Recall')\n",
        "  plt.title('Validation F1 Score, Precision, and Recall')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Metric Value')\n",
        "  plt.legend()\n",
        "\n",
        "  # Plot validation F1 Score, Precision, and Recall\n",
        "  plt.subplot(2, 2, 4)\n",
        "  plt.plot(data['epoch'], data['val_binary_io_u'], label='Validation Binary IoU')\n",
        "  plt.title('Validation Binary IoU')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Metric Value')\n",
        "  plt.legend()\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jw8Z3axYAx3V"
      },
      "outputs": [],
      "source": [
        "# Load the CSV file\n",
        "data = pd.read_csv(current_logger_dir)\n",
        "\n",
        "print(\"Metrics of\", current_model)\n",
        "show_training_metrics(data)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "TWUWHPKGJ0Mk",
        "d51sdFTOBH0u",
        "cWUoYri4826z",
        "uwfhtbiXkcgK",
        "kT4L2e1Lqyw2"
      ],
      "gpuType": "T4",
      "provenance": [],
      "mount_file_id": "1Pr4Bzg6qa8c5Khkr-f7jPNqPGfM21Tx0",
      "authorship_tag": "ABX9TyPZtdEoWqCCYJAkbPyhLjEL"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}